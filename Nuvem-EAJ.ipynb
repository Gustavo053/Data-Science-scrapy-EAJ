{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Links salvos na lista com sucesso\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from selenium import webdriver\n",
    "\n",
    "options = webdriver.FirefoxOptions()\n",
    "options.add_argument('headless')\n",
    "\n",
    "driver = webdriver.Firefox(executable_path = '/home/gustavo/Downloads/geckodriver-v0.29.0-linux32/geckodriver', options = options)\n",
    "urlLinks = 'https://ufrn.br/imprensa/noticias/filtros?text=eaj'\n",
    "driver.get(urlLinks)\n",
    "urlArray = []\n",
    "\n",
    "try:\n",
    "    body = driver.find_element_by_tag_name('body')\n",
    "    html = body.get_attribute('innerHTML')\n",
    "    soupPage = soup(html, 'html5lib')\n",
    "    #OBTÉM A QUANTIDADE DE PÁGINAS A PARTIR DO RESULTADO PESQUISADO\n",
    "    lastPage = int(driver.find_element_by_xpath(\"/html/body/div[3]/div/div[1]/section/section/nav/ul/li[8]/a\").text)\n",
    "    for pages in range(lastPage): \n",
    "        body = driver.find_element_by_tag_name('body')\n",
    "        html = body.get_attribute('innerHTML')\n",
    "        soupPage = soup(html, 'html5lib')\n",
    "        #CRIA UMA LISTA COM OS LINKS PARA CADA NOTÍCIA\n",
    "        linkList = soupPage.findAll(\"a\", class_='blue-link')\n",
    "        \n",
    "        #MONTA DINAMICAMENTE A URL E SALVA NA LISTA DE URLS.\n",
    "        for n in range(2,len(linkList)):\n",
    "            url = 'https://ufrn.br/' + linkList[n].get('href') + \"\\n\"\n",
    "            urlArray.append(url)       \n",
    "        #DÁ UM CLICK NO ELEMENTO '>' PARA A AVANÇAR PARA A PRÓXIMA PÁGINA\n",
    "        driver.find_element_by_xpath(\"//a[contains(text(),'>')]\").click()\n",
    "        #DELAY PARA CARREGAR A PRÓXIMA PÁGINA '(evita bugs)'\n",
    "        time.sleep(2)  \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "print('Links salvos na lista com sucesso')\n",
    "\n",
    "#RASPAGEM DE DADOS COM OS LINKS SALVOS A PARTIR DA RASPAGEM ANTERIOR\n",
    "\n",
    "def getGeneralText(urlArray):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        #JUNTA TODO O ARTIGO EM UMA ÚNICA STRING CONTENDO TODOS OS ARQUIVOS OBTIDOS NA RASPAGEM\n",
    "        for i in range(len(urlArray)):\n",
    "            driver.get(urlArray[i])\n",
    "            spanArray = driver.find_elements_by_css_selector(\"span[style='font-weight: 400;']\")\n",
    "            for j in range(len(spanArray)):\n",
    "                text += \" \" + spanArray[j].text \n",
    "            text += \"\\n\\n\"\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(e) \n",
    "    \n",
    "generalText = getGeneralText(urlArray)\n",
    "driver.close()\n",
    "\n",
    "print('Raspagem de dados finalizada')\n",
    "\n",
    "#GERAÇÃO DA WORDCLOUD\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "STOPWORDS = ['ver','principal','essa','vez','nas','mas',\n",
    "             'qual','principal','ele','ter','doença','pois','este',\n",
    "             'vez','ver principal','artigo principal','já',\n",
    "             'aos','pode','outro','artigo','desse',\n",
    "             'alguns','meio','entre','das','podem','esse',\n",
    "             'seu','também','são','quando','de', 'que','em',\n",
    "             'os','as','da','como','dos','ou','se','um','uma',\n",
    "             'para','na','ao','mais','por','não','ainda','muito','sua',\n",
    "             'a', 'é', 'o', 'e', 'no', 'do', 'toda', 'todo', 'estão',\n",
    "             'está', 'pela', 'pelo', 'fazer', 'foram', 'sendo', 'está',\n",
    "             'à', 'serão', 'foi', 'ser', 'tem', 'nos', 'sobre', 'cada',\n",
    "             'todos', 'abriu', 'vão', 'até', 'abriu', 'ofertando', 'com',\n",
    "             'anexo', '1º', 'minha', 'selecionar', 'escolher',\n",
    "             'possível', 'nesse', 'todas', 'falou', 'outros',\n",
    "             'recém', 'através', 'às', 'dia']\n",
    "\n",
    "import matplotlib.pyplot as plot\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def wordCloud(text):\n",
    "    maskArray = np.array(Image.open(\"cloud.jpeg\"))\n",
    "    cloud = WordCloud(background_color = \"white\",max_words = 200, mask = maskArray, stopwords = set(STOPWORDS))\n",
    "    cloud.generate(text)\n",
    "    cloud.to_file(\"wordCloud_EAJ.jpg\")\n",
    "    plot.figure()\n",
    "    plot.imshow(cloud, interpolation='bilinear')\n",
    "    plot.axis('off')\n",
    "    \n",
    "wordCloud(generalText)\n",
    "\n",
    "print('Nuvem plotada com sucesso')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
